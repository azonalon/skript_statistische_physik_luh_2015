\begin{description}
  \item[Bose-Gas bei $T=0$] 
    %
    \begin{align*}
      \Braket{\hat{n}_{s,\vec{k}}} = \begin{cases}
        0 & \quad\forall\, \vec{k} \neq 0 \\
        \ge 0 & \quad\forall\, \vec{k} = 0 , \quad \sum_{s}^{} \Braket{\hat{n}_{s,\vec{k}=0}} = N
      \end{cases} 
    \end{align*}
    %
    Das bedeutet der Grundzustand ist makroskopisch besetzt. Man nennt das
    Bose-Einstein-Kondensat. 
    %
    \begin{align*}
      \frac{N_0}{N} > 0 && N \to \infty 
    \end{align*}
    %
    Man kann daraus sehr leicht die Fluktuation der Teilchenzahlen berechnen.
    Wenn man das mit der Großkanonischen Beschreibung vergleicht, dann muss
    man um diesen Effekt zu bekommen das folgende machen
\end{description}
%
\begin{align*}
  \frac{1}{e^{\beta(\epsilon(\vec{k}) - \mu)} - 1} = \begin{cases}
    0 & \quad\forall\, \epsilon(\mathcal{k}) > \mu \\
    \infty & \text{ für } \epsilon(\vec{k} = 0) = \mu
  \end{cases} 
\end{align*}
%
Wir erreichen dass wenn das chemische Potential den festen Wert des Grundzustands
hat. Wir wollen die Funktion oben invertieren, also sollte die Funktion
$\mu(N)$ umkehrbar sein. Das ist im allgemeinen jedoch nicht möglich. Man braucht
eine Funktion die varriiert in abhängigkeit der Parameter. Physkialisch gesehen, 
was passiert da? Sobald es eine endliche Temeperatur gibt dann ist das Kondensat
gelöst. Dann kann man das großkanonische ensemble verwenden. in 3 dimensionen
ist das im allgeminen nicht der Fall. Wir können diesen Fall mit unserer berechnung
nicht berücksichtigen. Wir müssen also die gleichung korrigieren. Unser 
startpunkt war dabei die Summe oben. Wir hatten geschrieben
%
\begin{align*}
  N = \sum_{s, \vec{k}}^{} \Braket{\hat{n}_{s,\vec{k}}} = \sum_{n}^{} \Braket{\hat{n}_{s,\vec{k}=0}}
  + \sum_{s, \vec{k} \neq 0 }^{} \Braket{\hat{n}_{s,\vec{k}}}.
\end{align*}
%
Wenn man die Summe durch ein Integral ersetzt dann spielt ein Punkt keine rolle
und man kann wieder das Ergebnis von oben verwenden. Sie sehen, dass nun die
Zustandsgleichung ein bisschen anders ist als Vorher
%
\begin{align*}
  N = N_0 + \frac{v(2S+1}{\lambda_T^3} g_{\frac{3}{2}} (Z)
\end{align*}
%
Wir müssen nun diese Gleichung näher untersuchen. Für
%
\begin{align*}
  N_0 = 
  \begin{cases}
    0 &  T > T_c(\rho) \\
    N - \frac{V(2 S + 1}{\lambda_T^3} g_{\frac{3}{2}}(1) &  T < T_c(\rho)\\
  \end{cases} 
\end{align*}
%
%
\begin{align*}
  \frac{N_0 }{N} = 1 - \frac{\rho_c(T) }{\rho} = 1- \left( \frac{T}{T_c(\rho)} \right)^{\frac{3}{2}}
\end{align*}
%
Dies ist der Anteil des Kondensats.
%
\begin{align*}
  1  - \frac{N_0}{N} 
\end{align*}
%
Ist der nicht kondensierte Anteil. Wir können nun kurz analysieren was das
eigentlich bedeutet. Man hat ein Kondensat oberhalb der kritischen dichte.
Es verschwindet jedoch genau wenn die Dichte diesen Wert erreicht. Man 
kann das graphisch illustrieren. \\
Ausrduck Name vorname matrikelnummer\\
elektronisch name nachnahme \\
sprechzeiten 
\begin{table}[h!]
  \centering
  \begin{tabular}{c c c c c c}
     & & & nächste woche \\
    Mi & 11-12 & Mi & & vorlesungsfrei nach absprache \\
    & 14-16:30 & & 14-18 \\
    Do & 10-12 & Do & & \\
         &      &  & 14-16 \\
  \end{tabular}
\end{table}

% TODO: skizze
\subsection*{Freies ideales Fermi-Gas}
\emph{Schwabl Kapitel 4.2, 4.3}
%
\begin{align*}
  \epsilon(\vec{k}) = \frac{\hbar^2}{2 m} \vec{k}^2 && s = -S, -S + 1, \ldots , S
  && \text{ Entartung: } 2 S + 1 && S = \frac{1}{2} , \frac{3}{2}, \ldots
\end{align*}
%
Damit ist
%
\begin{align*}
  Z(\epsilon \ge 0) = \frac{2 S + 1) ((2 \pi m)^{\frac{d}{2}}}{k^d}
  \frac{1}{\Gamma\left( \frac{d}{2} \right)} \epsilon^{\frac{d}{2} - 1} \\
  \text{ Fermi-Dirac-Verteilung } \Braket{ \hat{n}_{\vec{k},s}} = 
  \frac{1}{e^{\beta(\epsilon(\vec{k}) - \mu)} + 1}
\end{align*}
%
Wir berechnen zuerst großkanonisch die Teilchenzahl
%
\begin{align*}
  N(T, \mu, V) = \sum_{\vec{k},s}^{} \Braket{\hat{n}_{\vec{k},s}} = 
  V \int_{0}^{ + \infty} \d{\epsilon} \frac{Z(\epsilon) 1}{e^{\beta(\epsilon-\mu)} + 1}
\end{align*}
%
Wir müssen dieses Integral analysieren indem wir für $Z$ diese besondere Form
verwenden.
%
\begin{align*}
  N(T, \mu, V)= \frac{V(2 S + 1}{\lambda_T^d} f_{\frac{d}{2}}(Z)
\end{align*}
%
mit der Fugazität $Z = e^{\beta \mu}$ und $\lambda_T = \sqrt{2 \pi m k_B T}
\frac{1}{h}$. 
%
\begin{align*}
  f_\alpha(Z) = \int_{0 }^{ + \infty} \d{x} x^{\alpha-1} \frac{1}{\frac{1}{z} e^x + 1} 
  \frac{1}{\Gamma(\alpha)} = 
  \sum_{m=1}^{\infty} (-1)^{n+1} \frac{z^n}{n^\alpha}
\end{align*}
%
%
\begin{align*}
  U(T, \mu, V) & = \sum_{\vec{k},s}^{} \epsilon(\vec{k}) \Braket{\hat{n}_{\vec{k},s}} \\
               & = V \int_{0}^{ + \infty} \d{\epsilon} Z(\epsilon) 
  \frac{\epsilon}{e^{\beta(\epsilon-\mu)} + 1} \\
  &  = V ( 2 S + 1) 
  \frac{1}{\lambda_T^d} f_{\frac{d}{2} + 1} (z) 
  \frac{d}{2} k_B T
\end{align*}
%
%
\begin{align*}
  \Omega(T, \mu, V) & = - k_B T \ln{Z_{GK}} = 
  - k_B T \sum_{\vec{k},s}^{} \ln{\left( 1 + e^{-\beta(\epsilon(\vec{k}) - \mu)} \right)} \\
  & = - k_B T V \int_{0}^{+ \infty} \d{\epsilon} Z(\epsilon) \ln{\left[ 1 + e^{-\beta(\epsilon- \mu)} \right]} \\
  & = - k_B T V (2  S + 1)
  (2 \pi m )^{\frac{d}{2}} \frac{1}{h^d} \underbrace{\frac{1}{\Gamma\left( \frac{d}{2} \right)}
  \int_{0}^{+ \infty} \d{\epsilon} \epsilon^{\frac{d}{2} - 1}\ln{
\left[ 1 + e^{- \beta (\epsilon - \mu)} \right]}}_{ = (k_B T) ^{\frac{d}{2}}
\frac{1}{\Gamma\left( \frac{d}{2} \right)}  \int_{0}^{\infty} x^{\frac{d}{2} - 1}
\ln{\left[ 1 + Z e^{-x} \right]}}
\end{align*}
%
%
\begin{align*}
  \frac{1}{\Gamma(\frac{d}{2})} \int_{0}^{ \infty} x^{\frac{d}{2} - 1}
  \ln{\left[  1 + Z e^{-x} \right]} = 
  \frac{1}{\Gamma\left( \frac{d}{2} \right)} \frac{Z}{d} x^{\frac{d}{2}}
  \ln{\left[ 1 + Z e^{-x} \right]} |_0^\infty
  - \frac{1}{\Gamma\left( \frac{d}{2} \right)} \int_{0}^{\infty}
  \d{x} \frac{2}{d} x^{\frac{d}{2}} 
  \underbrace{\frac{-z e^{-x}}{1 + z e^{-x}}}_{=  - \frac{1}{e^{x} \frac{1}{z} + 1}}
 \end{align*}
%
%
\begin{align*}
  \Omega(T, \mu, V) = k_B T V \left( 2 S + 1 \right) 
  \frac{1}{\lambda_T^d} \frac{2}{d} f_{\frac{d}{2} + 1}(z) = 
  - \frac{2}{d} U
\end{align*}
%
Wir können nun den Druck berechnen, da wir das großkanonische Potential ausgerechnent
haben
%
\begin{align*}
  P & = - \left( \pd{\Omega}{V} \right)_{T, \mu} = 
  - \frac{\Omega}{V} = \frac{2}{d} \frac{U}{V} 
  \implies U = \frac{PV d}{2}
\end{align*}
%
Im Grenzfall ist
%
\begin{align*}
  Z \ll 1 && \iff && \beta \mu \to -\infty && \iff && - \mu \gg k_B T
\end{align*}
%
%
\begin{align*}
  f_\alpha(z) = z - z^{-\alpha} z^2 + \mathcal{O}(z^3)
\end{align*}
%
Daraus folgt
%
\begin{align*}
  P V = \frac{2}{d} U \simeq V (2 S + 1) 
  \frac{1}{\lambda_T^d} k_B T \left[ z - z^{-\left( \frac{d}{2} + 1 \right)
  z^2 + \mathcal{O}(z^3)} \right]
\end{align*}
%
%
\begin{align*}
  N \simeq V (2 S + 1) 
  \frac{1}{\lambda_T^d} \left[ z - z^{-\frac{d}{2}} z^2 z^2 + \mathcal{O}(z^3) \right] (*)
\end{align*}
%
Das bedeutet
%
\begin{align*}
  \frac{P V }{N k_B T} & = 
  \frac{z - z ^{\left( - \frac{d}{2} + 1 \right) z^2 + \mathcal{O}(z^3)}}{
    (z - z ^{\left( - \frac{d}{2} \right) z^2 + \mathcal{O}(z^3)}) } \\
    & = 1 - \left( z^{-\left( \frac{d}{2} + 1\right)} - z^{-\frac{d}{2}} \right)Z
    + \mathcal{O} \\
    & = 1 + z^{-\left( \frac{d}{2} + 1 \right)} z + \mathcal{O}(z^2) \quad (+)
\end{align*}
%
%
\begin{align*}
  Z = \frac{N}{V} \frac{1 }{2 S + 1} \lambda_T^d 
\end{align*}
%
Aus $(*)$ folgt
%
\begin{align*}
  Z = \frac{N}{V} 
  \frac{1}{2 S + 1} \lambda_T^d
\end{align*}
%
und dann mit $(+)$
%
\begin{align*}
  PV = N k_B T \left[ 1 + z^{-\left( \frac{d}{2} + 1 \right)} 
  \frac{\rho }{2 S + 1} \lambda_T ^d \right]
\end{align*}
%
Dies ist die erste Quantenkorrektur zur Zustandsgleichung des idealen Gases für
Fermionen. Wenn man betrachtet, wann dies Gleichung erfüllt ist:
Wir haben angenommen dass $z \ll 1$ also
%
\begin{align*}
  \rho \lambda_T^d \ll 1 && T \to \infty && S \to \infty
\end{align*}
%
Bevor wir den Grenzfall $ z \gg 1 $ betrachten untersuchen wir den Fall
$T = 0$. 
%
\begin{align*}
  \Braket{\hat{n}_{s ,\vec{k}}} = \frac{1}{e^{\beta(\epsilon(\vec{k}) - \mu)} + 1}
  \underset{=}{T\to0} \begin{cases}
    0 & \text{ für } \epsilon(\vec{k}) > \mu \\
    1 & \text{ für } \epsilon(\vec{k}) < \mu \\
  \end{cases} 
\end{align*}
% TODO: Skizze
%
%
\begin{align*}
  \text{ Fermi-Energie } \epsilon_F = \mu \text{ für } T = 0\\
  \text{ Fermi-Temperatur } \epsilon_F = k_B T_F
\end{align*}
%
Das schöne an diesem Grenzfall ist, dass die Rechnung sehr einfach wird.
%
\begin{align*}
  N & = \sum_{\vec{k},s}^{} \Braket{\hat{n}_{\vec{k},s}} = 
  V \int_{0}^{+ \infty} \d{\epsilon} Z(\epsilon) \Omega(\epsilon_F - \epsilon) \\
  & = V (2 S + 1)
  (2 \pi m)^{\frac{d}{2}}\frac{1}{h^d} 
  \frac{1}{\Gamma\left( \frac{d}{2} \right)} \underbrace{\int_{0}^{\epsilon_F}
  \epsilon^{\frac{d}{2} - 1} \d{\epsilon}}_{ = \frac{2}{d} \epsilon_F^{\frac{d}{2}}}
\end{align*}
%
%
\begin{align*}
  \epsilon_F = \left( \rho
  \Gamma\left( \frac{d}{2} + 1 \right)/ (2S + 1) \right)^{\frac{2}{d}}
  \frac{h^2 }{2 \pi m}
\end{align*}
%
Beispiel 
%
\begin{align*}
  d = 3 && \epsilon_F 
  \left( \frac{6 \pi^2}{2 S + 1} \rho \right)^{\frac{2}{3}} 
  \frac{\hbar^2}{2 m}
\end{align*}
%
%
\begin{align*}
  E_0 = \sum_{\vec{k},s}^{} \epsilon(\vec{k}) \Braket{\hat{n}_{\vec{k},s}}
= U(T = 0)  = N \epsilon_F
\frac{\frac{d}{2}}{\frac{d}{2} + 1}
\end{align*}
%
%
\begin{align*}
  d = 3 && E_0 = \frac{3}{5} N \epsilon_F
\end{align*}
%
%
\begin{align*}
  \text{ Grenzfall } z \gg 1 && \iff && \beta \mu \gg 1
  && \iff && \mu > k_B T
\end{align*}
%
%
\begin{align*}
  d = 3 && \text{ Sommerfeld-Entwicklung } \equiv \text{ asymptotische Entwicklung 
der } f_\alpha(z)
\end{align*}
%
%
\begin{align*}
  f_{\frac{3}{2}} (z) = \frac{4}{3} \frac{1}{\sqrt{\pi}}
  (\ln{ z}) ^{\frac{3}{2}} \left[ 1 + \frac{\pi^2}{8}
  \frac{1}{(\ln{z})^2} + \ldots \right]
\end{align*}
%
Das funktioniert auch für die zweite Funktionen die wir brauchen, 
für die Energie haben wir
%
\begin{align*}
  f_{\frac{5}{2}} (z) = \frac{8}{15} \frac{1}{\sqrt{\pi}} (\ln{z})^{\frac{5}{2}}
  + \pi^{\frac{3}{2}}\frac{1}{3} (\ln{z})^{\frac{1}{2}} + \ldots 
\end{align*}
%
Sie können diese Formel verwenden um die Teilchenzahl als funktion von 
$z$ zu entwickeln. Damit ergibt sich
%
\begin{align*}
  \mu & = \epsilon_F \left[  1- \frac{\pi^2}{12} \left( \frac{T}{T_F} \right)^2
  + \mathcal{O}\left( \left( \frac{T}{T_F}^4 \right) \right)\right] \\
  U & = \frac{3}{5} N \epsilon_F \left[ 1 + \frac{5}{12} \pi^2 \left( \frac{T }{T_F} \right)^{2} 
+ \mathcal{O}\left( \left( \frac{T}{T_F} \right)^4 \right)\right]
\end{align*}
%
Wenn $z \gg 1$ dann ist $T \ll T_F$ und wir haben ein entartetes Fermi-Gas.
Man kann jetzt die Wärmekapazität berechnen:
%
\begin{align*}
  C_{V, N} = \dd{U}{T} = \frac{N  k_B \pi^2}{2} \frac{T }{T_F} \xrightarrow{T\to 0} 0
\end{align*}
%
% TODO: skizze

Beispiele sind 
% \begin{itemize}
%   % \item Elektronen im Metall $ \epsilon_F = \SI{1-10}{\electronvolt}$ $T_F = \SI{e4-e5}{\Kelvin}$
%   % \item Weiße Zwerge $\epsilon_F = \SI{1-10}{\electronvolt}$ $T_F = \SI{3e9}{\Kelvin}$
%   % \item \ce{He3}$ \epsilon_F = \SI{4e-4}{\electronvolt}$ $T_F = \SI{5}{\kelvin}$ theoretisch, experimentell \SI{1}{\Kelvin}.
% \end{itemize}

\subsection*{Vorlesung 19: Magnetismus und Ising-Modell}
\begin{description}
  \item[Klassische Physik] 
    %
    \begin{align*}
      H = \sum_{i=1}^{N}\frac{1}{2 m_i} \left[ \vec{P}_i - q_i \vec{A}(\vec{r}_i, t) \right]^2
      + \sum_{i=1}^{N} q_i \Phi(\vec{r}_i, t) + W (\{\vec{r}_i\})
    \end{align*}
    %
    %
    \begin{align*}
      Z(T, V, N, \vec{B}) = c \int_{\R^{3N}}^{V^N} \d{^{3N} r} e^{-\beta H}
    \end{align*}
    %
    %
    \begin{align*}
      G(T, V, N, \vec{B}) = - k_B T \ln{Z}
    \end{align*}
    %
    Magnetisierung
    %
    \begin{align*}
      \vec{M}(T, V, N, \vec{B}) = - \left( \pd{G}{\vec{B}} \right)_{T, V, N}
    \end{align*}
    %
  \item[Bohr-Van-Leeaven-Theorem]
    Es gibt keinen magnetismus in der klassichen statistischen Physik. Das heißt
    %
    \begin{align*}
      \vec{M}(\vec{B}) = 0 \quad\forall\, \vec{B}
    \end{align*}
    %
  \item[Beweis] Man macht eine Substitution
    %
    \begin{align*}
      \tilde{\vec{P}}_i = \vec{P}_i - q_i \vec{A}
    \end{align*}
    %
    Damit verschwindet die Abhängigkeit vom Vektorpotential. Mit der richtigen
    Eichung ist das Magnetfeld unabhängig von $\Phi$.
  \item[Quantenphysik]
    %
    \begin{align*}
      H = [\sum_{i=1}^{N} 
        \frac{( \vec{P}_i^2 )}{2 m_i} - \mu_i^z B
    ]    
  \end{align*}
    %
    Magnetisches Moment des Teilchens $i$ in $z$-Richtung
    %
    \begin{align*}
      \hat{\mu}_i^z = + \frac{q_i}{2 m_i}\left( \hat{L}_i^z + g_i \hat{S}_i^z \right)
      + \frac{q_i^2}{4 m_i} (\hat{x}_i^2 + \hat{y}_i^2) B
    \end{align*}
    %
    In der Regel wird der Zweite Term vernachlässigt.
    %
    \begin{align*}
      G(T, V, N, \vec{B}) & = - k_B T \ln{( \trace e ^{-\beta H})}\\
      M(T, V, N, \vec{B}) = - \left( \pd{G}{\vec{B}} \right)_{T, V, N} = 
      \Braket{
        \sum_{i}^{} \hat{\mu}_i^z
      }
    \end{align*}
    %
    Es gibt isotherme magnetische Suszeptibilität
    %
    \begin{align*}
      \chi_T(T, V, N, \vec{B}) = \left( \pd{\vec{M}}{\vec{B}} \right)_{T, V, N}
      = \left\{ \pd{M_i}{B_j} \right\}
    \end{align*}
    %
  \item[Beispiele]
    \begin{enumerate}[1)]
      \item Magnetismus von Atomen und Ionen
        \begin{itemize}
          \item Edelgase $\vec{L} + \vec{S} = 0$. Damit folgt Diamagnetismus, also
            $\chi_T < 0$.
          \item Ungerade Anzahl von Elektronen $( \ce{Na}, \ce{U^{4+}})$:
            $J^z = L^z + 2 S^z \neq 0$. Es gibt also Paramagnetismus
            $\chi_T > 0$, $\chi_T = \frac{C}{T}$. Man nennt diesen Zusammenhang
            auch \emph{Curie-Weiss-Gesetz}.
        \end{itemize}

      \item Magnetismus der Metalle \\
        Man hat Leitungselektronen, also Delokalisierte Elektronen im positiv
        geladenen Hintegrund. Dies ist letztlich ein Freies Fermi-Gas.
        Jetzt schalten wir ein Magnetfeld ein. Wir müssen aus dem hamilton-Operator
        den Teil nehmen der für das Magnetfeld relevant ist. Dazu machen wir die
        Vereinfachung, dass es nur Kopplung des Magnetfeldes mit dem Spin
        gibt.
        %
        \begin{align*}
          H = \sum_{i=1}^{N} 
          \frac{(\vec{P}_i^2)}{2 m_i} + 2 \mu_B S_i^z
        \end{align*}
        %
        Dabei ist $\mu_B = \frac{2 \hbar}{2 m_l}$. Die Einteilchen Eigenenergien
        %
        \begin{align*}
          \epsilon_\sigma(\vec{k}) = \frac{\hbar \vec{k}^2}{2 m_l} + \mu_B \cdot B \cdot \sigma
          && \text{ mit } \sigma = \pm 1 && S^z \Ket{\vec{k} r} = \frac{\hbar}{2} 
          \sigma \Ket{\vec{k} \sigma}
        \end{align*}
        %
        Man kann die Physik sehr gut verstehen wenn man das System bei $T=0$ betrachtet.
        In diesem Fall hat man die Situation, dass dispersion bei $B=0$ eine Parabel ist.
        Die Niveaus unter der Fermi-Energie sind besetzt, die anderen nicht.
        Man hat dabei für jedes Niveau ein up und ein down elektron. Wenn
        man nun das magnetfeld einschaltet, dann muss man die Dispersion nach
        oben oder unten verschieben, je nchdem ob man Spin Up oder Spin Down hat.
        Die Verschiebung ist dabei proportional zu $B \mu_B$. Man hat also nun
        mehr Elektronen mit Down Spin als mit Up. Man kann dann die Magnetisierung
        in $z$-Richtung explizit berechnen. Die magnetisierung ist
        der Erwartungswert des magnetischen Momentes. man bekommt dann
        %
        \begin{align*}
          M_z  = - \frac{e}{m_e} \Braket{\sum_{i}^{} S_i^z} = 
          - \mu_B (N_+ - N_-) > 0
        \end{align*}
        %
        Wir bekommen tatsächlich eine magnetisierung die Positiv oder Negativ ist, 
        je nach orientierung des Magnetfeldes. Man kann dies auch für tiefe Temperaturen
        berechnen aber man führt das letztlich nur auf den vorigen Weg zurück.
        Man bekommt dann einen Wert für die Suszeptibilität die auch
        Pauli-Suszeptibilität gennannt wird
        %
        \begin{align*}
          \chi_P = \mu_B^2 Z(\epsilon_F) V
        \end{align*}
        %
        Da der Wert größer als 0 ist nennt man das Phänomen
        auch Pauli-Paramagnetismus.

        Mit Kopplung zu $L^z$ und $x^2 + y^2: \chi_L = - \frac{\xi_p}{3}$. Dies
        ist der \emph{Landau-Diamagnetsimus}.
        Wenn das Magnetfeld in einem Metall sehr groß wird kann man kreisbewegung
        der Elektronen beobachten. Man kann das auch quantenmechanisch erklären.

        Es gibt Verschiedene Konventionen in der Physik, also sieht das ERgebnis
        nicht immer so aus wie oben. Man muss dann aufpassen in welchen 
        Einheiten die Werte definiert sind.
        
    \end{enumerate} 
\end{description}
    \begin{description}
      \item[Ising Modell] Wir haben lokalisierte Elektronen auf einem $d$-dimensionalen
        hyperkubischen Gitter. Lokalisierte heißt hier, dass sie sich nicht bewegen
        können, der einzige Freiheitsgrad ist also der Spin der Elektronen.
        Wir werden nun annehmen, dass es in dem System eine sehr anisotrope
        Austauschkopplung gibt. Wir beschränken uns dabei auf kurzreichweitige
        Wechselwirkungen, also solche mit den nächsten Nachbarn. Dass die
        Richtung sehr anisotop ist, bedeutet dass auch nur z.B. die $z$-Komponente
        des Spins koppelt. Der Hamilton operator schreibt sich dann zu
        %
        \begin{align*}
          H = - \sum_{\Braket{i,j}}^{} I_{i,j} S_i^z S_j^z + 
          \frac{2 \mu_B}{\hbar} \sum_{i=1}^{N} B_i S_i^z
        \end{align*}
        Die Summe geht dabei über alle Gitterplätze.
        Die standardnotatinon
        %
        \begin{align*}
          \sum_{\Braket{i,j}}^{}
        \end{align*}
        %
        Bedeutet eine Summer über alle Paare von nächsten Nachbarn.
        %
        Das könnte man noch aus der Quantenmechanik kennen:
        %
        \begin{align*}
          H = - J \vec{S}_1 \cdot \vec{S}_2 \to 
          - J_x S_1^x S_2^x + J_x S_1^x S_2^x + J_z S_1^z S_2^z
        \end{align*}
        %
        Das wichtige ist hier, dass es zwei räume gibt. Einen raum des Gitters
        und einen Raum des Spins. Wir nehmen allerdings an, dass für die richtung
        des Spins nur eine Komponente wichtig ist. $I$ ist nur ein Platzhalter
        für die Austauschkopplung. Wir werden das später noch konkretisieren.
        Jetzt müssen wir jedoch vorerst das Problem lösen. Dazu müssen wir
        wissen was Der Hilbert-Raum eines Elektronenspins eigentlich ist.
        %
        \begin{align*}
          \text{Hilbert-Raum } \mathbb{C}^{2N}
        \end{align*}
        %
        Wir dürfen und werden ein Tensorprodukt der Basen verwenden.

        Stellen sie sich nun vor man hätte keine Wechselwirkung. Dann wäre
        die Lösung einfach, die eigenzustände sind dann
        %
        \begin{align*}
          \Ket{\{s_i\}} = \Ket{s_1} \otimes \Ket{s_2} \otimes \ldots \otimes
          \Ket{s_N} \text{ mit } S_i^z \Ket{s_i} = \frac{\hbar}{2}
          \Ket{s_i}, \quad s_i = \pm 1
        \end{align*}
        %
        Alle Operatoren die wir hier haben kommutieren miteinander. Wir können
        das System also fast wie ein klassisches System behandeln. Der Grund
        warum wir dass Problem in 2 Dimensionen überhaupt lösen konnen ist,
        dass die Eigenzustände eine so einfache Form haben. Die Eigenenergien sind
        %
        \begin{align*}
          E(\{s_i\}) = -  \sum_{\Braket{i,j}}^{} I_{i,j} \frac{\hbar}{4}
          s_i s_j + \sum_{i}^{} \underbrace{B_i \mu_B}_{- H_i} s_i
        \end{align*}
        %
        Wir haben also die eigenzustände und die Eigenenergien, wir können
        also die Magnetisierung eines Eigenzustandes $\Ket{\{s_i\}}$ berechnen
        %
        \begin{align*}
          M(\Ket{\{s_i\}}) = - \frac{2 \mu_B}{\hbar} \Braket{\{s_i\}
            | \sum_{i}^{} S_i^z | \{s_i\}} = \underbrace{- \mu_B}_{=1} \sum_{i}^{} s_i
        \end{align*}
        %
        aus historischen Gründen haben wir $\mu_B$ gleich 1 gesetzt. Das ist 
        alles für die Eigenzustände gewesen. Wir haben nun also 
        alles um die Zustandssumme zu schreiben:
        %
        \begin{align*}
          Z & = \trace e^{-\beta H}  = \sum_{\{s_i\}}^{} 
          \Braket{\{s_i\} | e^{-\beta H} | \{s_i\}} \\
          & = \sum_{\{s_i\}}^{} e ^{-\beta E (\{s_i\})}
        \end{align*}
        %
        Damit ist dann,
        %
        \begin{align*}
          G(T, H) = - k_B T \ln{Z} 
        \end{align*}
        %
        Man kann damit zum Beispiel die Magnetisierung berechnen
        %
        \begin{align*}
          M(T, H) = - \left( \pd{G}{H} \right)_T = 
          \Braket{ \sum_{i}^{} s_i} = 
          \frac{1}{Z} \sum_{\{s_i\}}^{} \left( \sum_{j}^{} s_j \right)
          e^{-\beta E(\{si\})}
        \end{align*}
        %
        Das problem sind nun die Wechselwirkungen, wir haben also ein Summe  
        über $2^N$ Terme
        %
        \begin{align*}
          \sum_{\{s_i\}}^{} = \sum_{s_1 = \pm 1}^{} \sum_{s_2 = \pm 1}^{} \ldots\sum_{s_N = \pm 1}^{}
        \end{align*}
        %
        Angenommen wir haben nun ein Quadratisches Gitter mit $d=2$.  Und
        kantenlänge 10. Das bedeutet  wir haben $N= 10^2$. Und damit
        $2^{100} \approx 10^{30}$ Terme. Exakte Lösung in 
        $d = 1$ und $z$. Die Lösung in einer Dimension wird eine Hausübung sein,
        die Lösung in zwei Dimensionen ist jedoch viel schwieriger. Interessant
        ist jedoch, dass es exakte Lösungen gibt für Phasenübergänge bei
        $T_c > 0$ in $d=2$.

        Es gibt jedoch auch Näherungsverfahren, ein Beispiel ist die 
        
        \begin{itemize}
          \item Tief-und Hochtemperaturentwicklung
          \item Molekularfeldnäherung
          \item Monte-Carlo-Simulationen \\
            Diese werden auch Teil der dritten Computerübung sein.
        \end{itemize}
      
    \end{description}
\subsection*{Vorlesung 20: Ising-Modell und Transfermatrix-Methode}
\emph{Schwabl Kapitel 6.5 und Anhang F} \\
Das Ising Modell ist für uns wie eine klassische Energie die von der Spinkonfiguration
abhängt
%
\begin{align*}
  E(\{s_i\}) = - J \sum_{\Braket{i,j}}^{} s_i s_j - H \sum_{i}^{} s_i && s_i = \pm 1
\end{align*}
%
\begin{description}
  \item[Tiefe Temperatur] Wir werden nur den Fall $T=0$ diskutieren.
    \begin{itemize}
      \item $H=0$ \\ Grundzustand.  Eine konfigureation ist
        %
        Die einfache Formel für paare in einem kubischen Gitter:
        \begin{align*}
          \begin{cases}
            s_i = + 1 \quad\forall\,i & E_0 = - J N d, \quad m = \frac{M}{N} = +1 \\
            s_i = - 1 \quad\forall\, i & E_0 = - J N d, \quad m = -1 
          \end{cases} 
        \end{align*}
        Neben der Entartung haben wir auch eine spontante Symmetriebrechung.
        ($Z \to - Z$). Dies entspricht in unserem Modell $s_i \to - s_i$.
        %
        Das System hat eine Spiegelsymmetrie, der Grundzustand jedoch nicht mehr.
        Dies ist characteristisch für Phasenübergänge. Wenn der spin immer in die Gleiche
        richtung zeigt, dann nennt man das auch einen Ferromagneten. Es gibt also
        auch eine spontane Magnetisierung (Permanentmagnet). Antiferromagnetismus
        erhält mann wenn die Kopplung negativ ist ($J< 0$). In diesem Fall gibt es auch
        eine Symmetriebrechung und zwei Grundzustände. In diesem Fall wird die Energie
        edoch maximiert, das ist jedoch nicht was wir wollen. Wir beschränken
        uns hier auf den Fall des Ferromagnetismus.
      \item $H > 0$ \\
        Es gibt nur einen Zustand 
        %
        \begin{align*}
          s_i = +1 \quad\forall\, i, && E_0 = - J N d - H N
        \end{align*}
        %
      \item $H > 0$ \\
        Es gibt nur einen Zustand 
        %
        \begin{align*}
          s_i = -1 \quad\forall\, i, && E_0 = - J N d + H N
        \end{align*}
        %
    \end{itemize}
  \item[Hohe Temperaturen] Wir machen eine Taylor-Entwicklung für hohe Temperaturen.
    %
    \begin{align*}
      k_B T \gg J, H
    \end{align*}
    %
    Die Temperatur ist also viel größer als die Wechselwirkungsenergie die wir haben.
    Wir machen jetzt also eine Taylor-Entwicklung
    %
    \begin{align*}
      Z & = \sum_{ \{s_i\} }^{} e^{-\beta E (\{s_i\})} = \sum_{\{s_i\}}^{}
      \left[ 1 - \beta E (\{s_i\}) + \frac{1}{2 \beta^2 E^2 (\{s_i\})} + \mathcal{O}(\beta^3) \right] \\
       & = \sum_{\{s_i\}}^{} \bigg[ 1+ \beta J \sum_{\Braket{i,j}}^{}
        s_i s_j + \beta H \sum_{i}^{} s_i + \frac{1}{2} \left( \beta J \right)^2
        \sum_{\Braket{i,j}}^{} \sum_{\Braket{k, l}}^{} s_i s_j s_k s_l \\ & \quad + \frac{1}{2} (\beta H )^2 \sum_{i}^{} \sum_{j}^{} s_i s_j
         + \beta J \beta H \sum_{\Braket{i,j}}^{} \sum_{k}^{} s_i s_j s_k
       \bigg] + \mathcal{O}(\beta^3)
    \end{align*}
    %
    %
    \begin{align*}
      \sum_{s = \pm 1}^{} f(s) = \begin{cases}
        0 & \text{ ungerade } \\
        2 f(1) & \text{ gerade}
      \end{cases} 
    \end{align*}
    %
    Wir haben hier zum beispiel 3 Spin $s_i s_j s_k$, wir können also nie eine gerade 
    Potenz haben, deswegen wird der Term 0.
    %
    \begin{align*}
      \implies Z & = Z^N + \frac{1}{2}(\beta J)^2 \sum_{\{s_i\}}^{} \sum_{\Braket{i,j}}^{} 
      s_i^2 s_j^2 + \frac{1}{2} (\beta H)^2 \sum_{\{s_i\}}^{} \sum_{i}^{} s_i^2  \\
      & = Z^N \left[ 1 + \frac{1}{2} (\beta J)^2 \d{N} + \frac{1}{2} (\beta H)^2 N \right]
      + \mathcal{O}(\beta^3)
    \end{align*}
    %
    %
    \begin{align*}
      \implies G(T, H) = - k_B T \ln{Z} = - k_B T N \ln{Z} - \left\{ \frac{N}{2 k_B T} J^2 d+  H^2 \right\} + \mathcal{o}(\beta^2)
    \end{align*}
    %
    %
    \begin{align*}
      \implies M(T, H) =  - \left( \pd{G}{H} \right)_T = N
      \frac{H}{k_B T}
    \end{align*}
    %
    Wir können daraus zwei wichtige Punke folgern:
    %
    \begin{align*}
      \begin{cases}
        \lim_{H\to 0} \quad M = 0 & \text{ keine Spontane Magnetisierung} \\
        \chi_T = \left( \pd{M}{H} \right)_T = \frac{N}{k_B T} & \text{ ( Curie Gesetz )}
      \end{cases} 
    \end{align*}
    %
  \item[Phasenübergang bei $H\to0$]
    \begin{table}[h!]
      \centering
      \begin{tabular}{c c c c c c}
        $T = 0$ & $T \gg J, H$ \\
        Ferromagnet & Paramagnet \\
        $M \neq 0$  & $ M = 0$ \\
        Symmetriebrechung & Symmetrieerhaltung \\
      \end{tabular}
    \end{table}
    Damit ist die Kritische Temperatur $T_c \ge 0$. Wir könnten jetzt einfach
    eine Taylor-Entwicklung für hohe und tiefe Temperaturen machen, aber diese
    Vorgehensweise ist nicht besonders gut. Man kann damit nie wirklich
    singularitäten untersuchen wegen des endlichen konvergenzradius der Entwicklung.
    Man müsste dann eine unendliche Anzahl von Termen berücksichtigen. Eine 
    der wichtigsten Methoden ist die der Transfermatrix.
  \item[Transfermatrix-Methode] Wenn man eine Zustandsumme eines klassichen
    $d$ Dimensionalen Systems berechnen möchte kann man das über eine Matrix machen.
    Man versucht Probleme zurückzuführen auf solche, die man bereits gelöst hat.
    Deswegen ist diese Methode sehr beliebt. Es geht um die Berechnung des größten
    Eigenwertes meiner Transfermatrix. Dies ist gleichbedeutend mit der Berechnung
    des Grundzustandes eines $d$-dimensionalen Quantensystems. In zwei dimensionen
    hat man ein system von nicht wechselwirkenden Fermionen, deswegen kann 
    man es in diesem Fall einfach lösen. 
  \item[Das eindimensonale Ising-Modell] Um das Problem in einer Dimension zu verstehen
    muss man die Energie explizit ausschreiben
    %
    \begin{align*}
      E (\{s_i\})  = -J \sum_{i=1}^{N} s_i s_{i+1} -  H \sum_{i=1}^{N} s_i
    \end{align*}
    %
    %
    \begin{align*}
      Z &  = \sum_{\{s_i\}}^{} \exp \left[ \beta J \sum_{i=1}^{N} s_i s_{i+1} + \beta H \sum_{i=1}^{N} s_i \right] \\
        &= \sum_{\{s_i\}}^{} \prod_{i=1}^{N} \exp\left[ \beta J s_i s_{i+1}  + \frac{1}{2} \beta H ( s_i + s_{i+1}) \right]
    \end{align*}
    %
    Wir definieren jetzt die Transfermatrix 
    %
    \begin{align*}
      T(s, s') & = \exp\left[ \beta J s s' + \frac{1}{2}\beta H (s + s') \right] &&
      s, s' = \pm 1 \\
      &  = \begin{pmatrix}
      e^{\beta(J + H)} & e^{- \beta J} \\
      e^{- \beta J} & e^{\beta (J- H)} \\
      \end{pmatrix} 
    \end{align*}
    %
    %
    \begin{align*}
      Z = \sum_{s_1 = \pm 1}^{} \sum_{s_2 = \pm1}^{} \ldots \sum_{s_N = \pm 1}^{}
      T(s_1, s_2) \cdot T(s_2, s_3) \cdot \ldots \cdot T(s_{N-1}, s_N) \cdot 
      T(s_N, s_1)
    \end{align*}
    %
    Das ganze ist ein Matrixprodukt
    %
    \begin{align*}
      \sum_{s' = \pm 1}^{} T(s, s') T(s', s'') = T^2(s, s'')
    \end{align*}
    %
    Daraus folgt
    %
    \begin{align*}
      Z = \sum_{s_i = \pm 1}^{} T^N (s_1, s_1) = \trace T^N \lambda_+^N + \lambda_-^N
    \end{align*}
    %
    Wir schreiben direkt die Eigenwerte
    %
    \begin{align*}
      \lambda_{ \pm} = e^{\beta J} \cosh(\beta H) \pm \sqrt{
        e^{2 \beta J} \sinh^2\left( \beta H \right) + e^{ - 2 \beta J}
      } \\
      \text{ Nebenbedingung } \lambda_+ > \lambda_- > 0 \\
    \end{align*}
    %
     Der Logarithmus einer Summe ist nicht besonders einfach zu behandeln.
     %
     \begin{align*}
       G(T, H) = - k_B T \ln{ Z}  = - k_B T N \ln{ \lambda_+} - \underbrace{k_B T
       \ln{\left( 1 = \left( \frac{\lambda_-}{\lambda_+} \right)^N \right)}}_{\to 0 \text{ für } N \to \infty}
     \end{align*}
     %
     Eine funktion die analystisch in $\beta $ ist bleibt es auch. Der Rest ist standard.
     Wir haben die freie Enthalpie, also berechnen wir nun die Physikalischen Größen.
     %
     \begin{align*}
       M(T, H) & = - \left( \pd{G}{H} \right)_T =  N \frac{\sin(\beta h)}{\sqrt{\sinh^2(\beta H) + e^{- 4 \beta J}}} \\
               & \underset{H\to 0}{=} 
       \begin{cases}
         N \sign H & \text{ für } T\to 0 \\
         0 & \text{ für } T > 0 \\
       \end{cases}  \implies \quad T_c = 0
     \end{align*}
     %
     Die nächste größe ist die Suszeptibilität
     %
     \begin{align*}
       \chi_T = \left( \pd{M}{H} \right)_T = \frac{N}{k_B T}
       \frac{(\cosh(\beta H) e^{-4 \beta J})}{\left( \sinh^2 (\beta H)+ e^{-4 \beta J} \right) ^{\frac{3}{2}}}
       \simeq 
       \frac{N }{k_B T} e^{2 \beta J} = \begin{cases}
         \frac{N}{k_B T} & \text{ für } k_B T \gg J \\
         \infty & \text{ für } T\to0
       \end{cases} 
     \end{align*}
     Dies ist auch ein allgemeines Ergebnis bei der Kritischen Temperatur.
     Als übungsaufgabe dürfen wir einen Teil dieser Rechnung durchführen.
     Für die Freie Energie selbst braucht man nur den Größten Eigenwert.
     Wir fassen jetzt kurz zusammen was das in Zwei dimensionen bedeutet.
   \item[Zweidimensionales Ising-Modell]
     Wir haben ein periodisches Gitter mit der Kantenlänge $L$.
     %
     \begin{align*}
       s_{x,y} = s_{x + L, y} = s_{x, y+L}
     \end{align*}
     %
     %
     \begin{align*}
       E(\{s_i\}) = - J \sum_{x=1}^{L}\sum_{y=1}^{L} \left( 
         s_{x,y} s_{x+1, y} + s_{x,y} s_{x, y+1} 
       \right) - H 
       \sum_{x=1}^{L} \sum_{y=1}^{L} s_{x,y}
     \end{align*}
     %
     Wir definieren die Transfermatrix als eine $(2^L \times 2^L)$ Matrix:
     %
     \begin{align*}
       T(s_{x,1} s_{x,2} \ldots s_{x,L}, s_{x+1, 1} s_{x+1,2}, \ldots s_{x+1, 2}) \\
       = \exp\left[ \beta J \sum_{y=1}^{L} s_{x, y} s_{x+1,y} + 
         \frac{1}{2\left( s_{x,y} s_{x, y+1} + s_{x+1, y} s_{x+1, y+ 1} \right)}
         + \frac{\beta H}{2} \sum_{y=1}^{L} (s_{x,y} + s_{x+1, y})
       \right]
     \end{align*}
     %
     Wir können wieder die Zustandssumme als Produkt dieser Matrizen schreiben.
     Die wechselwirkung zwischen dem Nachbarspin ist hier relevant. 
     %
     \begin{align*}
       Z & = \trace T^L =  \sum_{i=1}^{Z^L} \lambda_i^L \\
     \end{align*}
     %
     %
     \begin{align*}
       \implies G \underset{=}{L\to \infty} - k_B T L \ln{ \lambda_1}
     \end{align*}
     %
     Weil $\lambda_1$ der größte Eigenwert ist. Das Problem ist, dass wir hier
     eine riesige matrix haben, die wir diagonalisieren müssen. Für das 
     zweidimensionale Modell kann man das aber noch machen. Wenn man die Matrix
     nicht per hand diadonalisieren kann, dann muss man numerische Simulationen starten.
     Mann kann schnell risiege Matrizen diagonalisieren die dünn besetzt sind.
     Eine beliebte Methode ist die Transfermatrix analytisch zu berechnen
     und sie dann numerisch zu diagonalisieren. Wir kehren nun zurück zum
     zweidimensionalen Ising-modell. Wir wollen die Ergebnisse kurz
     zusammenfassen. Man findet hier einen Phasenübergang
     vom Paramagnet zum Ferromagnet bei einer endlichen kritischen Temperatur
     $T_c$
     %
     \begin{align*}
       k_B T_c = \frac{2 J }{\operatorname{asinh}(1)} = \frac{2 J}{\ln{(1 + \sqrt{2})}} 
       \approx \SI{2.269}{\joule}
     \end{align*}
     %
     An diesem Punkt geschehen sehr interessante Dinge.
   \item [Kritisches Verhalten]
     %
     \begin{align*}
       M & \propto (T_c - T)^\beta , && \beta = \frac{1}{8} && (T < T_c)\\
       C_H & \propto \abs{T_c - T}^{-\alpha}, && \alpha = 0 \\
       \chi_T & \propto \abs{ T_c - T} ^{-\gamma}, && \gamma = \frac{7}{4} \\
       M \propto \abs{H}^{\frac{1}{8}}, && \delta = 15 && (T = T_c) \\
     \end{align*}
     Dieser Exponent ist ein sehr wichtiges Ergebnis der theoretischen Physik.
     Man findet bei Phasenübergängen immer die Gleichen exponenten finden.
     Diese hängen von der Dimension des Systems ab. Die berechnung dieses
     Exponenten einer der Hauptaufgaben der statistischen Physik. Das Ising-Modell
     ist sehr interessant, da es eine der wenigen ist, mit denen man diese Parameter
     berechnen kann.
  
\end{description}



\subsection*{Vorlesung 21 Molekularfeldnäherung}
\emph{Schwabl Kapitel 6.5}\\
Auf Englisch auch \emph{Mean-Field approximation}, Näherung des mittleren 
Feldes gennant. Sie werden beide Namen selbst z.B. in der deutschsprachigen
Literatur finden. Diese Methode ist grundlegend für die statistische Physik
und der Vielteilchenphysik. Man findet sie in vielen Feldern der Physik unter
verschiedenen Namen. In der Festkörperphysik gibt es z.B. die \emph{Hartree-Fock}
Näherung. Es stellt ein \emph{Variationsverfahren} dar. Zuerst kommt eine 
Wiederholung einiger notwendiger Grundlagen.

Wir haben ein System von $N$-Teilchen
%
\begin{align*}
  \mathcal{H} = \bigotimes_{i=1}^{N} \mathcal{H}_i, && H: \mathcal{H} \to \mathcal{H}.
\end{align*}
%
Wir beschreiben einen Zustand durch den hermitischen Dichteoperator
%
\begin{align*}
  \rho: \mathcal{H} \to \mathcal{H}
\end{align*}
%
Das Grundkonzept der statistischen Physik war, dass wir ein Funktional
der freien Energie formulieren können.
%
\begin{align*}
  F[\rho] = \trace_{\mathcal{H}} (\rho H) + k_B T \trace_\mathcal{H}(\rho \ln{\rho})
\end{align*}
%
Im Gleichgewicht muss man einen Zustand haben, der die freie Energie minimiert.
Aus dieser minimierung bekommen wir $\rho$
%
\begin{align*}
  \rho = \frac{1}{Z} e ^{-\beta H} = \trace_{\mathcal{H}} e^{-\beta H} , &&
  F = F[\rho_\text{min}] = - k_B T \ln{ Z}
\end{align*}
%
Das ist im wesentlichen das Problem, dass wir für die Systeme lösen müssen.
Wir berechnen entweder die Zustandsumme, oder die Erwartungswerte 
auf eine andere Art- und Weise.

Für ideale Systeme ohne Wechselwirkung gilt
%
\begin{align*}
  H = \sum_{i=1}^{N} H_i, && [H_i, H_j] = 0
\end{align*}
%
in diesem Fall ist es einfach. Wir können dann den Dichteoperator faktorisieren.
%
\begin{align*}
  \rho = \prod_{i=1}^{N} \rho_i && \rho_i = e^{-\beta H_i} \frac{1}{Z_1} && Z_i = \trace_{\mathcal{H}_i}
  e^{-\beta H_i} && [\rho_i, \rho_j] = 0
\end{align*}
%
%
\begin{align*}
  Z = \prod_{i=1}^{N} Z_i, && F = - k_B T \sum_{i=1}^{N} \ln{Z_i}
\end{align*}
Physikalisch ist das Problem dann gelöst. Auch wenn Mathematisch das ganze nicht
so klar ist. 

Der Ansatz der Molekularfeldnäherung ist, dass der Dichteoperator die
obige Form hat
%
\begin{align*}
  \rho^{\text{MF}} = \prod_{i=1}^{N} \rho_i^\text{MF} &&
  [\rho_i^\text{MF}, \rho_j^\text{MF}]
\end{align*}
%
Wir Minimieren $F[\rho]$in der Untermenge der $\rho^\text{MF}$. Wir erhalten
dadurch eine Obergrenze der Freien Energie.
%
\begin{align*}
  F^\text{MF} = F \left[ \rho_\text{min}^\text{MF} \right] \ge
  F^\text{exakt} = F [\rho_\text{min}]
\end{align*}
%
Man kennt das aus der Quantenmechanik, da versucht man zum Beispiel die Schrödinger-Gleichung
durch ein Variationsverfahren zu lösen. Ohne Wechselwirkung funktioniert das Modell exakt.
Mit Wechselwirkung jedoch hat man nur die erwähnte Obergrenze.

Auch sieht man dem Ausdruck nicht an wie gut oder schlecht die Approximation ist.
Wenn man zum Beispiel Hartree-Fock auf Atome mit mehreren Elektronen anwendet,
bekommt man sehr gute Eigenergien, aber die Wellenfunktionen sind trotzdem völlig
falsch.

\begin{description}
  \item[Beispiel] Zweikörper-Wechselwirkung
    %
    \begin{align*}
      H = \sum_{i\neq j = 1}^{N} V_{ij} \mathcal{O}_i \mathcal{O}_j
    \end{align*}
    %
    Wenn man zum Beispiel die Coloumb-Wechselwirkung schreibt als
    %
    \begin{align*}
      H = \frac{1}{2}\sum_{i \neq j = 1}^{N} - \frac{e^Z}{\epsilon_0 \abs{\vec{r}_i - \vec{r}_j}} n_i n_j
    \end{align*}
    %
    Wir müssen nun die Spur des Hamilton-Operators ausrechnen
    %
    \begin{align*}
      \left[ \rho^\text{MF} \right] = \sum_{i \neq j =1}^{N} V_{ij} \Braket{\mathcal{O}_i}_i \Braket{\mathcal{O}_j}_j
      + k_B T \sum_{i=1}^{N} \trace_{\mathcal{H}_1} \left( \rho_i^\text{MF } \ln{\rho_i}^\text{MF} \right)
    \end{align*}
    %
    wobei
    %
    \begin{align*}
      \Braket{\mathcal{O}_i}_i = \trace_{\mathcal{H}_i} \left( \mathcal{O}_i \rho_i^\text{MF} \right)
    \end{align*}
    %
    %
    \begin{align*}
      \Braket{\mathcal{O}_i \mathcal{O}_j} \simeq \Braket{\mathcal{O}_i}\Braket{\mathcal{O}_j}
    \end{align*}
    %
    Minimierung bezüglich $\rho_i^\text{MF}$ liefert
    %
    \begin{align*}
      \rho_i^\text{MF} = \frac{1}{Z_i} e^{- \beta H_i^\text{MF}} && Z_i = \trace_{\mathcal{H}_i} e ^{-\beta H_i^\text{MF}} && (3)
    \end{align*}
    %
    mit dem Hamilton Operator in der Midfield Näherung 
    %
    \begin{align*}
      H_i^\text{MF} = \sum_{j=1, j\neq i}^{N} m_j V_{ij} \mathcal{O}_i =  f_i \mathcal{O}_i  && (1)
    \end{align*}
    %
    die mittleren Felder sind
    %
    \begin{align*}
      m_i = \Braket{\mathcal{O}_i}_i,  && f_i = \sum_{j \neq i }^{}V_{ij} m_j && (2)
    \end{align*}
    %
    Wir haben hier eine Selbskonsistente Gleichungen: (1), (2) und (3).
  \item[Alternatives Verfahren]
    Wir können jetzt ein bisschen weiter gehen und nicht nur den Produkansatz machen
    von vorhin sondern man kann die $f_i$ und $f_j$ variieren.
    %
    \begin{align*}
      F[\rho^\text{MF}] \underset{(1)+(3)}{=}  F \left( \{m_i\} \right) = 
      F(\{f_i\})
    \end{align*}
    %
    Wir minimieren nun bezüglich $\{m_i\}$ beziehungsweise $\{f_j\}$.
    %
    \begin{align*}
      F\left[ \rho^\text{MF} \right] = \Braket{ H - H^\text{MF}}_\text{MF}
      - k_B T \ln{Z^\text{MF}}
    \end{align*}
    %
    Unsere Näherung vernachlässigt die Wechselwirkug der Teilchen und erzeugt
    ein mitteleres Potential der Wechselwirkung.
  \item[Anwendung auf das Ising-Modell] 
    %
    \begin{align*}
      H = - \sum_{\Braket{ij}}^{} I S_i^Z S_j^Z + \frac{2 \mu_b}{\hbar} B \sum_{i}^{}S_i^Z
    \end{align*}
    %
    Dies ist der Wechselwirkungsteil welcher schon die richtige Form besitzt.
    Wir ersetzen nun den Erwartungswert des Produktes durch das Produkt der 
    Erwartungswerte.
    %
    \begin{align*}
      H_i^\text{MF} = - f_i \frac{2}{\hbar} S_i^Z
    \end{align*}
    %
    Wir machen zusätzlich die Näherung, dass das Feld nicht vom Gitterplatz abhängt.
    Wir können die Energie der Spinkonfiguration schreiben
    %
    \begin{align*}
      E(\{s_i\}) = - J \sum_{\Braket{ij}}^{} s_i s_j - H_i \sum_{i}^{} s_i && s_i = \pm 1
    \end{align*}
    %
    Damit bekommen wir 
    %
    \begin{align*}
      E_i = - f s_i
    \end{align*}
    %
    Durch den Vergleich erhält man
    %
    \begin{align*}
      f_i = J \sum_{\Braket{ij}}^{} \Braket{s_i}_j + H = 2 d J m + H
    \end{align*}
    %
    %
    \begin{align*}
      m = \Braket{s_i}_i = \frac{M}{N} = \frac{1}{Z_j} \sum_{s_i = \pm 1}^{} e^{-\beta E_i} = \tanh(\beta f)
    \end{align*}
    %
    %
    \begin{align*}
      Z_i = \sum_{s_i = \pm 1}^{} e^{-\beta E_i} = 2 \cosh\left( \beta f \right)
    \end{align*}
    %
    Man kann die Zwei Gleichungen elimieren, um eine Selbstkonsistente zu bekommen.
    %
    \begin{align*}
      f= 2 d J \tanh(\beta f) + H
    \end{align*}
    %
    Äquivalent bekommen wir
    %
    \begin{align*}
      m = \tanh(\beta 2 d J m + \beta H)
    \end{align*}
    %
    $d$ ist die Dimension des Gitters.
    Wir haben jetzt Gleichungen welche die Felder bestimmen. Wenn wir sie lösen
    haben wir das Problem gelöst. $f$ ist einfach das effektive Magnetfeld das
    auf den Spin $i$ wirkt. 

    Alternativ könnte man die FreieEnergie als funktion der Parameter bestimmen
    mit dem Ansatz 
    %
    \begin{align*}
      H^\text{MF} = -  f s_i && \text{ mit } f = 2 d J m + H
    \end{align*}
    %
    Daraus folgt die Gibbsche-Freie-Enthalpie (wir haben ein Magnetfeld).
    %
    \begin{align*}
      G(m) = 
      N \left[ - J d \tanh^2(\beta 2 d J m + \beta H) 
        + J 2 d m \tanh(\beta 2 d J m + \beta H)
        - k_B t \ln{} ( 2 \cosh(\beta 2 d J m + \beta H))
      \right]
    \end{align*}
    %
    Am Mininimum ist $ \dd{G}{m} = 0$ also $m = \tanh(\beta 2 d J m + \beta H)$.
    Die zweite Gleichung ist wichtig für die Hausübung.
    Man kann dann überprüfen ob man wirklich ein Minimum hat:
    %
    \begin{align*}
      \dd{^2 G}{m^2} > 0
    \end{align*}
    %
    Wir fangen ohne Magnetfeld an ($H=0$)
    %
    \begin{align*}
      m = \tanh(\beta 2 d J m) \implies \frac{x}{\beta 2 d J} = \tanh(x)
    \end{align*}
    %
    Man kann die Lösung graphisch untersuchen. Man stellt dann fest
    %
    \begin{align*}
      & \beta 2 d J < 1 \iff  k_B T > 2 d J :&& 1 \text{Lösung} m = 0 \text{ ( Paramagnet )} \\
      & \beta 2 d J > 1 \iff  k_B T < 2 d J :&& 3 \text{Lösungen} m = 0 \text{ aber } G''(m=0) < 0 \implies \text{ Maximum }
      & \pm m_0 \text{ mit } G''( \pm m_0) > 0 \implies \text{ Minima }
    \end{align*}
    %
    Der kritische Punkt ist
    %
    \begin{align*}
      T_c^\text{MF} = \frac{2 d J}{k_B}
    \end{align*}
    %
    Wie lautet die Magnetisierung in der Nähe der kritischen Temperatur aus?
    Magnetisierung für $T\to T_c (m_0 \to 0)$.
    %
    \begin{align*}
      m_0 = \tanh( 2 d J \beta m_0) = \beta 2 d J m_0 - \frac{1}{3} (\beta 2 d J m_0)^3 
      + \mathcal{O}(m_0^3)
    \end{align*}
    %
    Dies kann man einfach Lösen
    %
    \begin{align*}
      m_0 = \sqrt{3} \sqrt{1 - \frac{T}{T_c}} \frac{T}{T_c} && (T < T_c) 
    \end{align*}
    %
  \item[Wärmekapazität]
    %
    \begin{align*}
      T > T_c : G(m=0) & = - N k_B T \ln{ Z} \implies C_H = - T (\pd{^2 G}{T^2})_H = 0 \\
      T < T_c : G(m_0) & \simeq - N k_B T \ln{Z} - \frac{3}{4} N k_B T \left( 1 - \frac{T}{T_c} \right)^2
      + \mathcal{O}\left( \left( 1 - \frac{T}{T_c} \right)^3 \right) \\
      T \to T_c \implies C_H & = \frac{3}{2} N k_B + \mathcal{o}\left( \left( 1 - \frac{T}{T_c} \right) \right)
    \end{align*}
    %
    Wenn das Magnetfeld nicht Null ist:
    %
    \begin{align*}
      m = \tanh(\beta 2 d J m + \beta H) \iff \tanh(x) = \frac{x - \beta H}{\beta 2 d J}
    \end{align*}
    %
  \item[Magnetisierung]
    %
    \begin{align*}
      \abs{\beta H}, \beta J \gg 1 (T\to 0) \implies m = \sign(H)
    \end{align*}
    %
    Eine weitere Näherung sind kleine Magnetisierung und Magnetfelder.
    Da kann man eine Taylor-Entwicklung machen
    %
    \begin{align*}
      m, H \to 0: m \simeq \beta 2 d J m + \beta H - \frac{1}{3} \left( \beta 2 d J m + \beta H \right)^3 + \ldots\\
      = \beta 2 d J m  - \frac{1}{3 } - \frac{1}{3} \left( \beta 2 d J m  \right)^3 + \beta H \\
      \iff \frac{1}{3} m^3 + m (\frac{T}{T_c})^2 \left( \frac{T}{T_c} - 1 \right) = 
      \left( \frac{T}{T_c} \right)^2 \frac{H}{k_B T_c}
    \end{align*}
    %
    Für $T= T_c$ ist
    %
    \begin{align*}
      m = \left( \frac{3 H}{k_B T_c} \right)^{\frac{1}{3}}
    \end{align*}
    %
    Für $ T > T_c$
    %
    \begin{align*}
      \lim_{H\to  0} m= 0 \implies \abs{m}^3 \ll \abs{m} \implies m = \frac{H}{k_B (T- T_c)} \\
      \chi_T = \frac{1}{k_B (T - T_c)}
    \end{align*}
    %
    Für $ T < T_c$
    %
    \begin{align*}
      \lim_{H\to  0} m = m_0 \sign H
    \end{align*}
    %
    Für $ T \to T_c$
    %
    \begin{align*}
      m = m_0 \sign H = \delta m \implies m = m_0 \sign H + \frac{H}{2 k_B (T_c - T)} \\
      \implies \chi_T = \frac{1}{2 k_B(T_c -T)}
    \end{align*}
    %
    
    
    
    
    
    

    
    
  
\end{description}


